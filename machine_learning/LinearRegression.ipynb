{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直线方程=70.386 x1+ 7.432 x2+ -1.4210854715202004e-14\n",
      "训练数据集得分：1.000\n",
      "测试数据集得分：1.000\n"
     ]
    }
   ],
   "source": [
    "#线性回归，又称最小二乘法（ordinary least square，OLS）\n",
    "#导入数据集拆分工具\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=2, n_informative=2, random_state=38)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "#输出拟合直线的系数和截距\n",
    "print('直线方程={:.3f}'.format(lr.coef_[0]),'x1+','{:.3f}'.format(lr.coef_[1]),'x2+','{}'.format(lr.intercept_))\n",
    "#由于有两个特征，每个特征值对应coef_的NumPy数组中的元素\n",
    "\n",
    "#线性回归的性能表现,查看一下拟合模型的得分\n",
    "print('训练数据集得分：{:.3f}'.format(lr.score(X_train, y_train)))\n",
    "print('测试数据集得分：{:.3f}'.format(lr.score(X_test, y_test)))\n",
    "#能得这么高分其实是没加噪声啦@_@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据集得分:0.530\n",
      "训练数据集得分:0.459\n"
     ]
    }
   ],
   "source": [
    "#测试下糖尿病数据集\n",
    "from sklearn.datasets import load_diabetes\n",
    "#分别载入数据集的数据和目标分类到X和y\n",
    "X, y = load_diabetes().data, load_diabetes().target\n",
    "#将数据集拆分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "#使用线性回归模型进行拟合\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "#查看得分\n",
    "print('测试数据集得分:{:.3f}'.format(lr.score(X_train, y_train)))\n",
    "print('训练数据集得分:{:.3f}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "# 这次模型的分数下降了许多T_T，这是由于实际数据的复杂度比手工合成的数据会高很多，\n",
    "# 使其表现大幅下降，同时分数差异那么大也说明了标准线性回归出现过拟合的问题。为此需要找一个模型能够控制模型的复杂度，即岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据集得分:0.433\n",
      "训练数据集得分:0.433\n"
     ]
    }
   ],
   "source": [
    "# 使用L2正则化的线性模型——岭回归，一种改良的OLS。\n",
    "# 这种保留全部特征变量，只改变特征变量的系数值来避免过拟合的方法被称为L2正则化。\n",
    "\n",
    "#导入岭回归\n",
    "from sklearn.linear_model import Ridge\n",
    "#使用岭回归对数据进行拟合\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print('测试数据集得分:{:.3f}'.format(ridge.score(X_train, y_train)))\n",
    "print('训练数据集得分:{:.3f}'.format(ridge.score(X_test, y_test)))\n",
    "\n",
    "# 可以看到两者都比线性回归得分低，同时这两者得分竟然一致（JOJO哒，这也在你的计算之中吗）。\n",
    "# 岭回归模型相对线性回归复杂度低，降低过拟合的可能性。\n",
    "# 同时模型复杂度低，意味着在训练集中表现越差，但模型在泛化方面的表现会更好。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#岭回归是在模型的简单性（使系数coef_趋近于零）和它的训练集上的性能之间实现平衡的一种模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
